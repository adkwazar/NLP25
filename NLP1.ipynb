{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b945437",
   "metadata": {},
   "source": [
    "<h3> Podsumowanie i uzupłenienie wiadomości o Napisach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22eaf158",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"To jest przykladowy tekst.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bcbbab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'T'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0] #zerowy znak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38c1db33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o j'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1:4] #znaki: 1,2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f2e25cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"ex\" in x #czy fragment \"ex\" jest w napisie x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b39d8fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"and\" not in x #czy prawdą jest, ze \"and\" nie znajduje sie w napisie x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6876a17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[-1] #ostatni znak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd91f1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'st przykladowy tekst.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[5:] #znaki od 5 do konca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4205710b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ekst.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[-5:] #ostatnie 5 znakow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4176ed5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['To', 'jest', 'przykladowy', 'tekst.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.split(\" \") #podziel tekst ze wzgledu na spacje i zapisz poszczegolne slowa do listy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0b9adbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T', ' jest przyklad', 'wy tekst.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.split(\"o\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bced23dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.startswith(\"Th\") #czy tekst zapisany w zmiennej x zaczyna sie od Th?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "029a9955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.endswith(\".\") #czy tekst zapisany w zmiennej x konczy sie kropką?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f9e2536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.count(\"e\") #policz liczbe wystapien litery \"e\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "507d683b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To jXst przykladowy tXkst.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.replace(\"e\",\"X\") #zamien wszystkie wystapienia \"e\" na \"X\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f588997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TO JEST PRZYKLADOWY TEKST.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.upper()  #zamien wszystkie znaki na duze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7581476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'to jest przykladowy tekst.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.lower()  #zamien wszystkie znaki na male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "152a6add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tO JEST PRZYKLADOWY TEKST.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.swapcase() #te co byly duze niech beda male, a male duze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf5054f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join([\"py\",\"t\",\"hon\"]) #zlacz liste slow w jedno slowo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8479b07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'py_t_hon'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"_\".join([\"py\",\"t\",\"hon\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4905ffd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1cbff06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation #znaki interpunkcyjne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3765ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0123456789'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.digits #cyfry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77c2bb3",
   "metadata": {},
   "source": [
    "<h3> NLTK - biblioteka do przetwarzania języka naturalnego"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc5d3be",
   "metadata": {},
   "source": [
    "<h4> Tokenizacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f92bb02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e290884e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_text = \"The cell is the basic structural and functional unit of all forms of life. Every cell consists of cytoplasm enclosed within a membrane; many cells contain organelles, each with a specific function. The term comes from the Latin word cellula meaning 'small room'. Most cells are only visible under a microscope. Cells emerged on Earth about 4 billion years ago. All cells are capable of replication, protein synthesis, and motility. Cells are broadly categorized into two types: eukaryotic cells, which possess a nucleus, and prokaryotic cells, which lack a nucleus but have a nucleoid region. Prokaryotes are single-celled organisms such as bacteria, whereas eukaryotes can be either single-celled, such as amoebae, or multicellular, such as some algae, plants, animals, and fungi. Eukaryotic cells contain organelles including mitochondria, which provide energy for cell functions; chloroplasts, which create sugars by photosynthesis, in plants; and ribosomes, which synthesise proteins.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0edc0c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The cell is the basic structural and functional unit of all forms of life.', 'Every cell consists of cytoplasm enclosed within a membrane; many cells contain organelles, each with a specific function.', \"The term comes from the Latin word cellula meaning 'small room'.\", 'Most cells are only visible under a microscope.', 'Cells emerged on Earth about 4 billion years ago.', 'All cells are capable of replication, protein synthesis, and motility.', 'Cells are broadly categorized into two types: eukaryotic cells, which possess a nucleus, and prokaryotic cells, which lack a nucleus but have a nucleoid region.', 'Prokaryotes are single-celled organisms such as bacteria, whereas eukaryotes can be either single-celled, such as amoebae, or multicellular, such as some algae, plants, animals, and fungi.', 'Eukaryotic cells contain organelles including mitochondria, which provide energy for cell functions; chloroplasts, which create sugars by photosynthesis, in plants; and ribosomes, which synthesise proteins.']\n"
     ]
    }
   ],
   "source": [
    "print(sent_tokenize(ex_text)) #podzial na sentencje"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3a4bab",
   "metadata": {},
   "source": [
    "<h4> Zadanie1: Porównaj zastosowanie metody split z kropką oraz metody sent_tokenize na tekście: \"Mr. Smith is a scientist. He is also a very good teacher.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "066e3879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'cell', 'is', 'the', 'basic', 'structural', 'and', 'functional', 'unit', 'of', 'all', 'forms', 'of', 'life', '.', 'Every', 'cell', 'consists', 'of', 'cytoplasm', 'enclosed', 'within', 'a', 'membrane', ';', 'many', 'cells', 'contain', 'organelles', ',', 'each', 'with', 'a', 'specific', 'function', '.', 'The', 'term', 'comes', 'from', 'the', 'Latin', 'word', 'cellula', 'meaning', \"'small\", 'room', \"'\", '.', 'Most', 'cells', 'are', 'only', 'visible', 'under', 'a', 'microscope', '.', 'Cells', 'emerged', 'on', 'Earth', 'about', '4', 'billion', 'years', 'ago', '.', 'All', 'cells', 'are', 'capable', 'of', 'replication', ',', 'protein', 'synthesis', ',', 'and', 'motility', '.', 'Cells', 'are', 'broadly', 'categorized', 'into', 'two', 'types', ':', 'eukaryotic', 'cells', ',', 'which', 'possess', 'a', 'nucleus', ',', 'and', 'prokaryotic', 'cells', ',', 'which', 'lack', 'a', 'nucleus', 'but', 'have', 'a', 'nucleoid', 'region', '.', 'Prokaryotes', 'are', 'single-celled', 'organisms', 'such', 'as', 'bacteria', ',', 'whereas', 'eukaryotes', 'can', 'be', 'either', 'single-celled', ',', 'such', 'as', 'amoebae', ',', 'or', 'multicellular', ',', 'such', 'as', 'some', 'algae', ',', 'plants', ',', 'animals', ',', 'and', 'fungi', '.', 'Eukaryotic', 'cells', 'contain', 'organelles', 'including', 'mitochondria', ',', 'which', 'provide', 'energy', 'for', 'cell', 'functions', ';', 'chloroplasts', ',', 'which', 'create', 'sugars', 'by', 'photosynthesis', ',', 'in', 'plants', ';', 'and', 'ribosomes', ',', 'which', 'synthesise', 'proteins', '.']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(ex_text)) #podzial na slowa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b324825",
   "metadata": {},
   "source": [
    "<h4> Zadanie2: Zdefiniuj funkcję, która dla danego tekstu zwraca liste słów z małej litery."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff12483",
   "metadata": {},
   "source": [
    "<h4> Zadanie3: Załaduj plik tekstowy o nazwie \"example_text.txt\", a następnie zapisz pod zmienną  $txt\\_words$  liste słów (z małej litery) występujących w tekście. Dodatkowo: <br>\n",
    "    \n",
    "- Wyświetl pierwsze 20 słów.\n",
    "- Ile słów znajduje się w tekście?\n",
    "- Ile występuje słów unikatowych?\n",
    "- Wyznacz tzw. miarę Herdana  $C=\\frac{\\log V}{\\log M}$ , gdzie  V  - liczba różnych słów,  M  - liczba wszystkich słów.\n",
    "- Ile razy wystąpiło słowo $woman$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6400e4a9",
   "metadata": {},
   "source": [
    "Pobierz korpus https://data.nls.uk/data/digitised-collections/a-medical-history-of-british-india/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c11c4c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No', '.', '1111', '(', 'Sanitary', '),', 'dated', 'Ootacamund', ',', 'the']\n"
     ]
    }
   ],
   "source": [
    "#Tokenizacja korpusu\n",
    "\n",
    "from nltk.corpus import PlaintextCorpusReader #do czytania kolekcji dokumentow\n",
    "\n",
    "\n",
    "corpus_root = 'nls-text-indiaPapers/' #nazwa katalogu w ktorym znajdują sie dokumenty tekstowe\n",
    "wordlists = PlaintextCorpusReader(corpus_root, '.*', encoding='latin1') #pod zmienna wordlists zapisz wszystkie pliki wsytepujace w sciezce podanej powyzej\n",
    "corpus_tokens = wordlists.words()  #metoda do tokenizacji tego zbioru dokumentow i zapisaniu w postaci listy tokenów (słów)\n",
    "\n",
    "print(corpus_tokens[:10]) #wyswietl pierwsze 10 slow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2780c27a",
   "metadata": {},
   "source": [
    "<h4> Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8a31623",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b18de59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stopwords Corpus  This corpus contains lists of stop words for several languages.  These are high-frequency grammatical words which are usually ignored in text retrieval applications.  They were obtained from: http://anoncvs.postgresql.org/cvsweb.cgi/pgsql/src/backend/snowball/stopwords/  The stop words for the Romanian language were obtained from: http://arlc.ro/resources/  The English list has been augmented https://github.com/nltk/nltk_data/issues/22  The German list has been corrected https://github.com/nltk/nltk_data/pull/49  A Kazakh list has been added https://github.com/nltk/nltk_data/pull/52  A Nepali list has been added https://github.com/nltk/nltk_data/pull/83  An Azerbaijani list has been added https://github.com/nltk/nltk_data/pull/100  A Greek list has been added https://github.com/nltk/nltk_data/pull/103  An Indonesian list has been added https://github.com/nltk/nltk_data/pull/112 '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.readme().replace('\\n', ' ') #opis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "edbc1b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'before', 'was', 'nor', 'm', 'most', 'mightn', 'on', 'wouldn', 're', \"isn't\", \"hasn't\", 'will', 'again', 'at', 'ma', 'o', 'than', \"won't\", \"it's\", 'did', \"should've\", 'below', \"she's\", 'theirs', 'didn', 'of', 'her', 'each', 'do', 'that', 'into', 'can', 'hers', 'why', 'should', 'here', 'more', 'those', 'had', 'such', 'yourselves', 'then', 'ours', 'against', 'needn', 'shouldn', 'i', 'any', 'them', 'up', 'for', 'from', 'after', 'but', 'ourselves', 'or', 'now', 'll', 'is', 'being', 'in', 'when', \"aren't\", 'are', 'not', 'so', 'this', 'be', 'your', 'he', \"couldn't\", 'as', \"you're\", \"you've\", 'about', 'him', \"shouldn't\", 'shan', 'has', 'having', \"shan't\", 'with', 'too', 'their', 'where', 'our', 'an', \"doesn't\", 'we', 'same', 'out', 'down', \"needn't\", 'my', 'through', 'while', 'does', 'which', \"hadn't\", 'very', 'only', 'further', 'ain', 'other', 'during', 'between', 'few', \"wouldn't\", 'you', \"mustn't\", 'y', 'yourself', 'because', 'doing', 'all', \"that'll\", 'were', 'herself', 'its', 'am', 'they', \"didn't\", \"haven't\", 'myself', \"you'll\", 'a', 'hasn', \"you'd\", 'some', 'aren', 'by', 'to', 'haven', 'itself', 'don', 'couldn', 'themselves', 've', 'isn', 'himself', 'under', 'me', 'off', 'she', 'above', 'and', \"wasn't\", 's', 'whom', 'these', 'it', 'doesn', 'weren', 'won', 'just', 'wasn', 'how', 'there', \"weren't\", \"don't\", 'mustn', 'what', 'd', 'his', 'the', 'been', 't', 'yours', 'once', \"mightn't\", 'both', 'hadn', 'have', 'until', 'over', 'no', 'if', 'own', 'who'}\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words(\"english\")) #angielskie stopwords\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a320d06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arabic', 'azerbaijani', 'basque', 'bengali', 'catalan', 'chinese', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'greek', 'hebrew', 'hinglish', 'hungarian', 'indonesian', 'italian', 'kazakh', 'nepali', 'norwegian', 'portuguese', 'romanian', 'russian', 'slovene', 'spanish', 'swedish', 'tajik', 'turkish']\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.fileids()) #inne języki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88672459",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_sentence = \"This is an example 1, showing off stop words filtration that occur using NLTK library.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f473f0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'an', 'example', '1', ',', 'showing', 'off', 'stop', 'words', 'filtration', 'that', 'occur', 'using', 'NLTK', 'library', '.']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(ex_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "63bc7c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'example', '1', ',', 'showing', 'stop', 'words', 'filtration', 'occur', 'using', 'NLTK', 'library', '.']\n"
     ]
    }
   ],
   "source": [
    "print([elem for elem in word_tokenize(ex_sentence) if elem not in stop_words ]) #bez stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7091494",
   "metadata": {},
   "source": [
    "<h4> Zadanie4: Zapisz do listy  $pure\\_words$  słowa występujące w napisie  $ex\\_sentence$  niebędące stop words, znakami interpunkcyjnymi czy cyframi (oczywiście w sposób automatyczny)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300411d0",
   "metadata": {},
   "source": [
    "<h4> Zadanie5: Utwórz słownik zawierający jako klucze  stopwords  a wartościami niech będzie liczba ich występień (ze wszystkich dokumentów zawartych w 'nls-text-indiaPapers/'). Które z nich występowało najczęściej?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4334700a",
   "metadata": {},
   "source": [
    "<h4> Klasyfikacja języka na podstawie stop words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68b14dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_text = \"La cellule est l'unité biologique structurelle et fonctionnelle fondamentale de tous les êtres vivants connus. C'est la plus petite unité vivante capable de se reproduire de façon autonome. La science qui étudie les cellules est appelée biologie cellulaire.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9339fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize #tokenizacja ze względu na interpunkcje i spacje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "94aaf973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['La', 'cellule', 'est', 'l', \"'\", 'unité', 'biologique', 'structurelle', 'et', 'fonctionnelle', 'fondamentale', 'de', 'tous', 'les', 'êtres', 'vivants', 'connus', '.', 'C', \"'\", 'est', 'la', 'plus', 'petite', 'unité', 'vivante', 'capable', 'de', 'se', 'reproduire', 'de', 'façon', 'autonome', '.', 'La', 'science', 'qui', 'étudie', 'les', 'cellules', 'est', 'appelée', 'biologie', 'cellulaire', '.']\n"
     ]
    }
   ],
   "source": [
    "ex_tokens = wordpunct_tokenize(ex_text)\n",
    "\n",
    "print(ex_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "026bb804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arabic': 0, 'azerbaijani': 1, 'basque': 0, 'bengali': 0, 'catalan': 5, 'chinese': 0, 'danish': 2, 'dutch': 1, 'english': 0, 'finnish': 2, 'french': 9, 'german': 0, 'greek': 0, 'hebrew': 0, 'hinglish': 3, 'hungarian': 1, 'indonesian': 1, 'italian': 4, 'kazakh': 0, 'nepali': 0, 'norwegian': 2, 'portuguese': 2, 'romanian': 3, 'russian': 0, 'slovene': 1, 'spanish': 4, 'swedish': 1, 'tajik': 0, 'turkish': 1}\n"
     ]
    }
   ],
   "source": [
    "language_ratios = {} #tworze pusty slownik\n",
    "\n",
    "ex_words = [word.lower() for word in ex_tokens] #zamieniam wszystkie litery na male \n",
    "unique_words_set = set(ex_words) #slowa unikatowe zapisuje w postaci zbioru\n",
    "\n",
    "for language in stopwords.fileids(): #dla kazdego jezyka \n",
    "    stopwords_set = set(stopwords.words(language)) #do stopwords_set zapisuje stopwords (danego jezyka) w formie zbioru\n",
    "    common_elements = unique_words_set.intersection(stopwords_set) #przeciecie zbiorow (A.intersection(B) to inaczej A∩B)\n",
    "    language_ratios[language] = len(common_elements) #zaliczam ile wspolnych elementow ma dany jezyk a wystepujace w tekscie stop words\n",
    "    \n",
    "\n",
    "print(language_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad2455bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "french\n"
     ]
    }
   ],
   "source": [
    "most_rated_language = max(language_ratios, key=language_ratios.get) #zapisuje jezyk ktory ma najwiecej stop_words w tekscie\n",
    "print(most_rated_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba35397e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'de', 'les', 'est', 'c', 'et', 'se', 'l', 'qui', 'la'}\n"
     ]
    }
   ],
   "source": [
    "print(unique_words_set.intersection(set(stopwords.words(most_rated_language)))) #jakie są to słowa? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8dcebb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'se'}\n"
     ]
    }
   ],
   "source": [
    "#ciekawe są stop_words słoweńskie wystepujace w tekscie \n",
    "\n",
    "print(unique_words_set.intersection(set(stopwords.words('slovene')))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3a5c94",
   "metadata": {},
   "source": [
    "<h3> Zastosowanie wyrażeń regularnych w NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a446c96",
   "metadata": {},
   "source": [
    "- [abc] <-- a lub b lub c\n",
    "- [A-Z] <-- od A do Z\n",
    "- [^X] <-- wszystko z wyjątkiem X\n",
    "- . <-- cokolwiek\n",
    "- \\d <-- dowolna cyfra od 0 do 9\n",
    "- \\D <-- wszystko z wyjątkiem cyfr [^d]\n",
    "- \\s <-- spacja\n",
    "- \\S <-- wszystko co nie jest spacją\n",
    "- \\w <-- a-z, A-Z, cyfry, podkreślenie _\n",
    "- *<-- żadne lub dowolnej długości powtórzenie, np ca*t znaczy ct, cat, caat, caaat...\n",
    "- +<-- jedno lub więcej powtórzenie, np ca+t znaczy cat, caat, caaat...\n",
    "- ? <-- żadne wystąpienie lub jedno wystąpienie, np pyt?hon znaczy pyhon lub python\n",
    "- {n} <-- znaczy, że coś ma nastąpić n razy\n",
    "- {n,m} <-- znaczy, że coś ma nastąpić między n a m razy np ab{1,3}c znaczy abc, abbc, abbbc\n",
    "- (X|Y) <-- X lub Y\n",
    "- ^x <-- znaczy, że od x ma sie zacząć wyraz\n",
    "- x$ <-- znaczy, że na x ma sie kończyc wyraz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64d5e68",
   "metadata": {},
   "source": [
    "<h4> Zadanie6: Podaj po dwa przykłady wyrazów (mające sens lub nie), które spełniają następujące wyrażenia regularne:\n",
    "    \n",
    "    \n",
    "    \n",
    "- '.ma.*'\n",
    "- 'meal?'\n",
    "- 'go{2,6}gle'\n",
    "- 'a[knm]e'\n",
    "- 'b[^a]d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2f580046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #biblioteka do wyrażeń regularnych w Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "da49049e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['women', 'women', 'women', 'woman', 'woman', 'woman', 'woman', 'woman', 'woman', 'woman', 'woman', 'woman', 'women', 'woman', 'women', 'women', 'woman', 'women', 'woman', 'women', 'woman', 'woman', 'woman', 'woman', 'women', 'women', 'women', 'women', 'women', 'woman', 'woman', 'women', 'women', 'women', 'women', 'women', 'women', 'woman', 'woman', 'women', 'women', 'women']\n"
     ]
    }
   ],
   "source": [
    "#Uwaga: txt_words trzeba sobie utworzyc w zadaniu 3\n",
    "\n",
    "womaen_strings=[w for w in txt_words if re.search('^wom[ae]n$', w)] #znajdź w liście wyrazów txt_words słowa spełniające podane wyrażenie regularne. Co ono oznacza?\n",
    "print(womaen_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e1e785",
   "metadata": {},
   "source": [
    "<h4> Zadanie7: Wykonaj analogiczne przeszukiwanie z wzorcem 'wom[ae]n' i porównaj otrzymane wyniki."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8d8910",
   "metadata": {},
   "source": [
    "<h4> Zadanie8: Wykonaj analogiczne przeszukiwanie, tym razem poszukując słów o łącznej liczbie znaków 13, które zaczynają się od 'a'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b15c01c",
   "metadata": {},
   "source": [
    "<h4> Zadanie9: Wykonaj analogiczne przeszukiwanie, tym razem poszukując słów o łącznej liczbie znaków 13, które nie zaczynają się od małej litery.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954af0a4",
   "metadata": {},
   "source": [
    "<h4> Własna tokenizacja z użyciem wyrazeń regularnych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aff15e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e3339cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(\"[a-zA-Z]+\") #tak definiuje slowo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ce4417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"The genome of Bacteroides vulgatus was found to contain DNA that belongs to a virus they called BV01. Next, they had to determine whether the virus could escape or reinfect the host. The researchers found that conditions in the gut may act to stimulate the activity of BV01.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2627b8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'genome', 'of', 'Bacteroides', 'vulgatus', 'was', 'found', 'to', 'contain', 'DNA', 'that', 'belongs', 'to', 'a', 'virus', 'they', 'called', 'BV', 'Next', 'they', 'had', 'to', 'determine', 'whether', 'the', 'virus', 'could', 'escape', 'or', 'reinfect', 'the', 'host', 'The', 'researchers', 'found', 'that', 'conditions', 'in', 'the', 'gut', 'may', 'act', 'to', 'stimulate', 'the', 'activity', 'of', 'BV']\n"
     ]
    }
   ],
   "source": [
    "s_tokenized = tokenizer.tokenize(s)\n",
    "\n",
    "print(s_tokenized)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
