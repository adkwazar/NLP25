{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15bfc6dc",
   "metadata": {},
   "source": [
    "<h3> Rozwa≈ºamy tweety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "815ed306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def get_data():\n",
    "    return csv.reader(open(\"training.1600000.processed.noemoticon.csv\", \"rt\", encoding=\"latin-1\"))\n",
    "\n",
    "labels = []\n",
    "texts = []\n",
    "\n",
    "for i, line in enumerate(get_data()): \n",
    "    labels.append(int(int(line[0])/4))\n",
    "    texts.append(line[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8294238c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36ab057d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6eeb518a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c24d4395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08026124",
   "metadata": {},
   "source": [
    "<h2> Sieci rekurencyjne (LSTM), model do klasyfikacji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f30693",
   "metadata": {},
   "source": [
    "<h4> LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8499b6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozpoczynam trening\n",
      "Epoch 1 | Loss: 36.1836\n",
      "Epoch 2 | Loss: 25.0502\n",
      "Epoch 3 | Loss: 17.1462\n",
      "Epoch 4 | Loss: 11.7116\n",
      "Epoch 5 | Loss: 8.2658\n",
      "Epoch 6 | Loss: 6.2544\n",
      "Epoch 7 | Loss: 4.6534\n",
      "Epoch 8 | Loss: 3.9906\n",
      "Epoch 9 | Loss: 3.0620\n",
      "Epoch 10 | Loss: 2.2881\n",
      "Epoch 11 | Loss: 2.4341\n",
      "Epoch 12 | Loss: 2.0429\n",
      "Epoch 13 | Loss: 1.4872\n",
      "Epoch 14 | Loss: 1.3573\n",
      "Epoch 15 | Loss: 1.3931\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torchtext.vocab import GloVe\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchtext\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\") #duze litery bƒôda automatyczie na ma≈ÇƒÖ zamienione, mozna by uzyc word_tokenize tez\n",
    "glove = torchtext.vocab.GloVe(name=\"6B\", dim=50)\n",
    "\n",
    "\n",
    "#tekst -> indeksy\n",
    "def text_to_indices(text):\n",
    "    return [glove.stoi.get(token, 0) for token in tokenizer(text)]  # 0 = indeks dla nieznanych s≈Ç√≥w\n",
    "\n",
    "\n",
    "#klasa dla danych\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.data = [torch.tensor(text_to_indices(t), dtype=torch.long) for t in texts]\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "dataset = TextDataset(X_train, y_train)\n",
    "\n",
    "#collate_fn do obs≈Çugi paddingu i d≈Çugo≈õci\n",
    "def collate_batch(batch):\n",
    "    sequences, labels = zip(*batch)\n",
    "\n",
    "    #sortuje malejƒÖco po d≈Çugo≈õci (wymagane przez pack_padded_sequence)\n",
    "    seq_lens = [len(seq) for seq in sequences]\n",
    "    sorted_indices = sorted(range(len(seq_lens)), key=lambda i: -seq_lens[i])\n",
    "    sequences = [sequences[i] for i in sorted_indices]\n",
    "    labels = torch.tensor([labels[i] for i in sorted_indices])\n",
    "\n",
    "    #paduje sekwencje do najd≈Çu≈ºszej\n",
    "    padded_seqs = pad_sequence(sequences, batch_first=True)  \n",
    "    lengths = torch.tensor([len(seq) for seq in sequences])  # rzeczywiste d≈Çugo≈õci\n",
    "\n",
    "    return padded_seqs, lengths, labels\n",
    "\n",
    "#DataLoader z naszym collate_fn i do obs≈Çugi batcha\n",
    "loader = DataLoader(dataset, batch_size=250, shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "#Wlasciwy model\n",
    "class Klasyfikator_LSTM(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(glove.vectors, freeze=False)  # Wbudowane embeddingi GloVe, freee=F sprawia ze embeddingi nie bƒôdƒÖ aktualizowane\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        embedded = self.embedding(x) \n",
    "        packed_input = pack_padded_sequence(embedded, lengths.cpu(), batch_first=True, enforce_sorted=True) #chowamy paddingi przed RNN\n",
    "        packed_output, (hn, cn) = self.lstm(packed_input) #dane przechodzƒÖ przez LSTM\n",
    "        last_hidden = hn[-1]  #bierzemy ostatni stan ukryty\n",
    "        output = self.fc(last_hidden)  #klasyfikacja na podstawie ostatniego stanu ukrytego\n",
    "        return output\n",
    "\n",
    "embedding_dim = 50\n",
    "hidden_size = 20\n",
    "num_classes = 2\n",
    "\n",
    "model = Klasyfikator_LSTM(embedding_dim, hidden_size, num_classes)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "print(\"Rozpoczynam trening\")\n",
    "for epoch in range(15):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        inputs, lengths, targets = batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs, lengths)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71ecad7",
   "metadata": {},
   "source": [
    "<h3> Jak to wyglƒÖda na zbiorze treningowym?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "555ed32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Dok≈Çadno≈õƒá: 0.9957\n",
      "\n",
      "üìä Szczeg√≥≈Çowy raport:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      7981\n",
      "           1       0.99      1.00      1.00      8019\n",
      "\n",
      "    accuracy                           1.00     16000\n",
      "   macro avg       1.00      1.00      1.00     16000\n",
      "weighted avg       1.00      1.00      1.00     16000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Ewaluacja modelu\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in loader:\n",
    "        inputs, lengths, targets = batch\n",
    "        outputs = model(inputs, lengths)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.tolist())\n",
    "        all_labels.extend(targets.tolist())\n",
    "\n",
    "#dok≈Çadnosƒá\n",
    "acc = accuracy_score(all_labels, all_preds)\n",
    "print(f\"\\nüîç Dok≈Çadno≈õƒá: {acc:.4f}\")\n",
    "\n",
    "#szczeg√≥≈Çowy raport\n",
    "print(\"\\nüìä Szczeg√≥≈Çowy raport:\")\n",
    "print(classification_report(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738fe75d",
   "metadata": {},
   "source": [
    "<h3> Jak to wyglƒÖda na zbiorze testowym?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5a75b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Dok≈Çadno≈õƒá: 0.7262\n",
      "\n",
      "üìä Szczeg√≥≈Çowy raport:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.72      0.73      2018\n",
      "           1       0.72      0.73      0.73      1982\n",
      "\n",
      "    accuracy                           0.73      4000\n",
      "   macro avg       0.73      0.73      0.73      4000\n",
      "weighted avg       0.73      0.73      0.73      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset2 = TextDataset(X_test, y_test)\n",
    "loader2 = DataLoader(dataset2, batch_size=250, shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in loader2:\n",
    "        inputs, lengths, targets = batch\n",
    "        outputs = model(inputs, lengths)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.tolist())\n",
    "        all_labels.extend(targets.tolist())\n",
    "\n",
    "#dok≈Çadnosƒá\n",
    "acc = accuracy_score(all_labels, all_preds)\n",
    "print(f\"\\nüîç Dok≈Çadno≈õƒá: {acc:.4f}\")\n",
    "\n",
    "#szczeg√≥≈Çowy raport\n",
    "print(\"\\nüìä Szczeg√≥≈Çowy raport:\")\n",
    "print(classification_report(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3c2f8d",
   "metadata": {},
   "source": [
    "<h3> Inne wersje sieci rekurencyjnych"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046f414e",
   "metadata": {},
   "source": [
    "* biLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9ed02a",
   "metadata": {},
   "source": [
    "self.lstm = nn.LSTM(embedding_dim, hidden_size, batch_first=True, bidirectional=True)\n",
    "\n",
    "self.fc = nn.Linear(hidden_size * 2, num_classes) #bo wyjscie ma teraz wymiar 2 * hidden_size\n",
    "\n",
    "--> W forward:\n",
    "\n",
    "packed_output, (hn, cn) = self.lstm(packed_input)\n",
    "\n",
    "forward_final = hn[0]\n",
    "\n",
    "backward_final = hn[1] \n",
    "\n",
    "final_hidden = torch.cat((forward_final, backward_final), dim=1)\n",
    "\n",
    "output = self.fc(final_hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a89422",
   "metadata": {},
   "source": [
    "* GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0abc72",
   "metadata": {},
   "source": [
    "self.gru = nn.GRU(embedding_dim, hidden_size, batch_first=True)  \n",
    "self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "--> w forward\n",
    "\n",
    "packed_output, hn = self.gru(packed_input) \n",
    "\n",
    "last_hidden = hn[-1] \n",
    "\n",
    "output = self.fc(last_hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1aa8d9",
   "metadata": {},
   "source": [
    "<h1> SNLI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59ebec5",
   "metadata": {},
   "source": [
    " https://nlp.stanford.edu/projects/snli/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ae1864",
   "metadata": {},
   "source": [
    "<h4> Zadanie1 (2 pkt). Pobierz dane. Zadanie polega na klasyfikacji pary zda≈Ñ (tzw. przes≈Çanka i hipoteza) do jednej z 3 kategorii przy pomocy sieci rekurencyjnych (LSTM/biLSTM lub GRU):\n",
    "    \n",
    "   <br> \n",
    "    \n",
    "- E (entailment, czyli z pierwszego zdania wynika drugie)\n",
    "- C (contradiction, czyli drugie zdanie jest w sprzeczno≈õci z pierwszym)\n",
    "- N (neutral, drugie zdanie jest neutralne w stosunku do pierwszego)\n",
    "    \n",
    "    <br>\n",
    "   \n",
    "Dla przyk≈Çadu:\n",
    "    \n",
    "(Dzisiaj jest czwartek. Jutro jest piƒÖtek) -> E\n",
    "    \n",
    "(Dzisiaj jest czwartek. Jutro jest poniedzia≈Çek) -> C\n",
    "    \n",
    "(Dzisiaj jest czwartek. Wczoraj pada≈Ço) -> N\n",
    "    \n",
    "    \n",
    " Uwagi i wskaz√≥wki:\n",
    "- zastosuj embeddingi 50D (lub wiƒôksze je≈ºeli bƒôdzie taka konieczno≈õƒá)\n",
    "- w wyniku kodowania  zda≈Ñ wej≈õciowych otrzymujemy dwa wektory (wektor√≥w) dla przes≈Çanki i hipotezy. Te wektory najlepiej nastƒôpnie skonktatenowaƒá, ewentualnie z jakim≈õ przerywnikiem typu \"implies\"\n",
    "- u≈ºywaj batch√≥w (np. 1000)\n",
    "- wyr√≥≈ºnij zbi√≥r walidacyjny celem okre≈õlenia optymalnej topologii sieci\n",
    "- analizuj dok≈Çadno≈õƒá na zbiorze treningowym i walidacyjnym co epokƒô (tak≈ºe graficznie)\n",
    "- przedstaw graficznie warto≈õƒá funkcji kosztu w kolejnych epokach\n",
    "- potestuj r√≥≈ºne zestawy parametr√≥w (jak hidden size, funkcje aktywacji, dropout, batchnormalizacjƒô itd...)\n",
    "- sprawd≈∫ dok≈Çadno≈õƒá na zbiorze testowym (przynajmniej 10% wszystkich danych) dla najlepszego modelu\n",
    "- je≈ºeli proces trenowania bƒôdzie trwa≈Ç zbyt d≈Çugo to zmniejsz rozwa≈ºany zbi√≥r danych! :) Mimo wszystko finalnie powiniene≈õ u≈ºyƒá pe≈Çnego zbioru (zapraszam do pracowni! :))\n",
    "    \n",
    "    \n",
    "Dok≈Çadno≈õƒá na zbiorze testowym vs liczba punkt√≥w za zadanie   \n",
    "* poni≈ºej 65 --> 0.5 pkt\n",
    "* 65-70 --> 1  pkt\n",
    "* 70-75 --> 1.5 pkt\n",
    "* ponad 75 --> 2 pkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33a0a4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  annotator_labels         captionID     gold_label               pairID  \\\n",
      "0        [neutral]  3416050480.jpg#4        neutral  3416050480.jpg#4r1n   \n",
      "1  [contradiction]  3416050480.jpg#4  contradiction  3416050480.jpg#4r1c   \n",
      "2     [entailment]  3416050480.jpg#4     entailment  3416050480.jpg#4r1e   \n",
      "3        [neutral]  2267923837.jpg#2        neutral  2267923837.jpg#2r1n   \n",
      "4     [entailment]  2267923837.jpg#2     entailment  2267923837.jpg#2r1e   \n",
      "\n",
      "                                           sentence1  \\\n",
      "0  A person on a horse jumps over a broken down a...   \n",
      "1  A person on a horse jumps over a broken down a...   \n",
      "2  A person on a horse jumps over a broken down a...   \n",
      "3              Children smiling and waving at camera   \n",
      "4              Children smiling and waving at camera   \n",
      "\n",
      "                              sentence1_binary_parse  \\\n",
      "0  ( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...   \n",
      "1  ( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...   \n",
      "2  ( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...   \n",
      "3  ( Children ( ( ( smiling and ) waving ) ( at c...   \n",
      "4  ( Children ( ( ( smiling and ) waving ) ( at c...   \n",
      "\n",
      "                                     sentence1_parse  \\\n",
      "0  (ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...   \n",
      "1  (ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...   \n",
      "2  (ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...   \n",
      "3  (ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...   \n",
      "4  (ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...   \n",
      "\n",
      "                                           sentence2  \\\n",
      "0  A person is training his horse for a competition.   \n",
      "1      A person is at a diner, ordering an omelette.   \n",
      "2                  A person is outdoors, on a horse.   \n",
      "3                  They are smiling at their parents   \n",
      "4                         There are children present   \n",
      "\n",
      "                              sentence2_binary_parse  \\\n",
      "0  ( ( A person ) ( ( is ( ( training ( his horse...   \n",
      "1  ( ( A person ) ( ( ( ( is ( at ( a diner ) ) )...   \n",
      "2  ( ( A person ) ( ( ( ( is outdoors ) , ) ( on ...   \n",
      "3  ( They ( are ( smiling ( at ( their parents ) ...   \n",
      "4             ( There ( ( are children ) present ) )   \n",
      "\n",
      "                                     sentence2_parse  \n",
      "0  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...  \n",
      "1  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...  \n",
      "2  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...  \n",
      "3  (ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VB...  \n",
      "4  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NN...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_json(\"snli_1.0/snli_1.0_train.jsonl\", lines = True)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a3f8e9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(550152, 10)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "40d305eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A person on a horse jumps over a broken down airplane.'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"sentence1\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2d216ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A person is training his horse for a competition.'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"sentence2\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a9652a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"gold_label\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07458b92",
   "metadata": {},
   "source": [
    "<h2> Dostrajanie modelu (Fine-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e4d6ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327e94b0",
   "metadata": {},
   "source": [
    "BERT - oparty o tzw. architekturƒô Transformers, jak trenowany?\n",
    "\n",
    "Zadania:\n",
    "- Masked Language Modeling (MLM) ‚Äî zgadywanie brakujƒÖcych s≈Ç√≥w w zdaniach,\n",
    "- Next Sentence Prediction (NSP) ‚Äî przewidywanie, czy zdanie B jest kontynuacjƒÖ zdania A."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c9a446",
   "metadata": {},
   "source": [
    "Przyk≈Çad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c1fc77",
   "metadata": {},
   "source": [
    "* bert-base-uncased - ok 110 milion√≥w parametr√≥w (w tym embeddingi token√≥w, parametry ka≈ºdej warstwy Transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42efee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\") #tokenizator na modelu jƒôzykowym BERT (ang) -> dobre rozumienie jezyka"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6e0356",
   "metadata": {},
   "source": [
    "Inne:\n",
    "* bert-base-multilingual-cased <- wielojƒôzykowy\n",
    "* polbert <- typowo polski, trenowany m.in. na Wikipedia\n",
    "* herbert-base-case <- te≈º polski (https://huggingface.co/allegro/herbert-base-cased)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420417f3",
   "metadata": {},
   "source": [
    "* Dodaje warstwƒô do klasyfikacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c59314e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2) #buduje model klasyfikacji w oparciu o BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffbc4b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    \"This product is amazing! Definitely worth buying, it meets all my expectations.\",\n",
    "    \"Customer service was really helpful and fast, I will definitely come back again!\",\n",
    "    \"The quality of this product is top-notch, I am very satisfied with the purchase.\",\n",
    "    \"Everything works flawlessly, I am really happy with this transaction!\",\n",
    "    \"I highly recommend this store, delivery was fast, and the product was exactly as described.\",\n",
    "    \n",
    "    \"Unfortunately, the product was damaged upon arrival, and customer service did not respond to my inquiry.\",\n",
    "    \"This product completely failed to meet my expectations. I'm very disappointed with the quality.\",\n",
    "    \"Delivery was delayed by several days, and getting in touch with the company was very difficult. I do not recommend.\",\n",
    "    \"The product doesn't work as described, and the company offers no technical support.\",\n",
    "    \"The website was confusing and poorly designed, making the whole buying process frustrating.\"\n",
    "]\n",
    "\n",
    "labels = [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c44d97c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = tokenizer(reviews, truncation=True, padding=True) #przycina dluzsze teksty (modele czesto majƒÖ limit); padding dodaje 0 zeby wyrownac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f249975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "dataset = TextDataset(encodings, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1abe9a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:13, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.653600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.689700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.595000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.524600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.446000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.363000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.263900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15, training_loss=0.48978143334388735, metrics={'train_runtime': 15.6797, 'train_samples_per_second': 1.913, 'train_steps_per_second': 0.957, 'total_flos': 385416585000.0, 'train_loss': 0.48978143334388735, 'epoch': 3.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\", #gdzie zapisze model\n",
    "    num_train_epochs=3,  #liczba epok\n",
    "    per_device_train_batch_size=2, #rozmiar batcha\n",
    "    logging_dir=\"./logs\", #gdzie zapisze logi (dane z treningu)\n",
    "    logging_steps=2,  #co ile batchow zapisac logi ->> mozna na bie≈ºaco sprawdzac jak model sie uczy\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset, #mozna tez dorzucic zbior walidacyjny eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83f4d160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\"Very nice product.\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "predictions = torch.argmax(outputs.logits, dim=1)\n",
    "print(predictions)  #0 lub 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2eeac82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\"Very bad product.\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "predictions = torch.argmax(outputs.logits, dim=1)\n",
    "print(predictions)  #0 lub 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0168775",
   "metadata": {},
   "source": [
    "<h4> Zadanie2 (2 pkt): Wybierz co najmniej 3 kandydat√≥w na prezydenta. Stw√≥rz zbi√≥r co najmniej 100 wypowiedzi na osobƒô, a nastƒôpnie zbuduj klasyfikator na bazie istniejƒÖcego modelu - w oparciu o wypowied≈∫ tekst przewiduje kt√≥ry kandydat m√≥g≈Ç to powiedzieƒá.\n",
    "    \n",
    "    \n",
    "Uwagi i wskaz√≥wki:\n",
    "- mo≈ºesz oprzeƒá siƒô na modelu herbert-base-cased \n",
    "- pobieranie wypowiedzi najlepiej zrealizuj w spos√≥b automatyczny (np. selenium)\n",
    "- mo≈ºe warto wybraƒá wypowiedzi z debat, poszukaj odpowiednich bibliotek w python do pobierania napis√≥w z youtube; w przypadku d≈Çu≈ºszych wypowiedzi podziel je na kr√≥tsze -> kilka zda≈Ñ\n",
    "- zadbaj o jako≈õƒá danych! Pamiƒôtaj, ≈ºe to jest podstawa sukcesu! (dobre dane + dobry model = sukces, s≈Çabe dane + dowolony model = pora≈ºka). Usu≈Ñ ewentualne duplikaty. W przypadku tweet√≥w rozwa≈º czy warto uwzglƒôdniƒá tak≈ºe przekierowania\n",
    "- podziel dane na zbi√≥r trenignowy/walidacyjny/testowy (7:2:1); wyznacz dok≈Çadno≈õci na tych zbiorach\n",
    "- sprawdz bezpo≈õrednio model na przyk≈Çadowych wypowiedziach \n",
    "- mo≈ºe warto rozbudowaƒá czƒô≈õƒá klasyfikacyjnƒÖ, poszukaj jak to zrobiƒá"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c40dee5",
   "metadata": {},
   "source": [
    "<h4> Uzupe≈Çnienie (automatyczne pobieranie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0cd73f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.microsoft import EdgeChromiumDriverManager\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad52aff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Service(\"C:\\\\Users\\\\Adrian\\\\Desktop\\\\Dydaktyka\\\\NLP\\\\web\\\\msedgedriver.exe\")\n",
    "browser = webdriver.Edge(service=service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e7e7922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Join me tomorrow, April 29th‚Äîin Warren, Michigan at 6:00PM Eastern!\n",
      "A conversation about online child predators with Homeland Security and John Rich: PLS Repost!\n",
      "Sleepy Joe Biden, THE WORST PRESIDENT IN THE HISTORY OF THE UNITED STATES, has allowed millions and millions of Criminals, many of them murderers, drug dealers, and people released from prisons and mental institutions from all around the world, to enter our Country through it‚Äôs\n",
      "Following my Day One Executive Order, the Office of Personnel Management will be issuing new Civil Service Regulations for career government employees. Moving forward, career government employees, working on policy matters, will be classified as ‚ÄúSchedule Policy/Career,‚Äù and will\n",
      "This is the hand of the man that the Democrats feel should be brought back to the United States, because he is such ‚Äúa fine and innocent person.‚Äù They said he is not a member of MS-13, even though he‚Äôs got MS-13 tattooed onto his knuckles, and two Highly Respected Courts found\n",
      "The United States has a chance to do something that should have been done DECADES AGO. Don‚Äôt be Weak! Don‚Äôt be Stupid! Don‚Äôt be a PANICAN (A new party based on Weak and Stupid people!). Be Strong, Courageous, and Patient, and GREATNESS will be the result!\n"
     ]
    }
   ],
   "source": [
    "# Zmienna do przechowywania tweet√≥w\n",
    "tweets = []\n",
    "tweets_to_scrape = 5 #ile chcemy \n",
    "\n",
    "url = \"https://twitter.com/realdonaldtrump\"\n",
    "browser.get(url)\n",
    "\n",
    "\n",
    "scroll_pause_time = 2  # czas na za≈Çadowanie nowych tweet√≥w (przy przewijaniu)\n",
    "\n",
    "while len(tweets) < tweets_to_scrape:\n",
    "    tweet_elements = browser.find_elements(By.XPATH, '//article//div[@lang]')\n",
    "    for tweet_element in tweet_elements:\n",
    "        try:\n",
    "            tweet_text = tweet_element.text\n",
    "            print(tweet_text) #tego nie trzeba wyswietlac, wrzucilem tylko zeby pokazac\n",
    "            tweets.append(tweet_text.replace(\"\\n\",\"\"))\n",
    "        except Exception as e:\n",
    "            print(f\"Cos poszlo nie tak ;/ {e}\")\n",
    "\n",
    "    if len(tweets) >= tweets_to_scrape:\n",
    "        break\n",
    "\n",
    "    #przewijanie w d√≥≈Ç, aby za≈Çadowaƒá wiƒôcej tweet√≥w\n",
    "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(scroll_pause_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3977fe97",
   "metadata": {},
   "source": [
    "<h4> Uzupe≈Çnienie (regularyzacja)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb901e6a",
   "metadata": {},
   "source": [
    "W sieciach neuronowych czƒôsto mo≈ºe dochodziƒá do zjawiska przetrenowania. ZwiƒÖzane jest to m.in. z du≈ºƒÖ swobodƒÖ w wyborze liczby parametr√≥w. Jak temu przeciwdzia≈Çaƒá?\n",
    "\n",
    "- u≈ºyƒá wiƒôcej danych do trenowania\n",
    "- zbudowaƒá mniejszƒÖ sieƒá (=mniej parametr√≥w)\n",
    "- dzielenie wag (weight sharing), jak np w konwolucyjnych sieciach neuronowych zastosowanie kernela dla wszystkich pozycji w obrazie\n",
    "- odpowiednie wczesne zako≈Ñczenie procesu uczenia (kontrolowane np poprzez zbi√≥r walidacyjny)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd9b2f3",
   "metadata": {},
   "source": [
    "Co mo≈ºna zrobiƒá wiƒôcej?\n",
    "- zwiƒôkszenie danych (czƒôsto na podstawie istniejƒÖcych przyk≈Çad√≥w)\n",
    "- normalizacja danych (np BatchNormalizacja)\n",
    "- u≈õrednianie modeli\n",
    "- dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a650b496",
   "metadata": {},
   "source": [
    "-> Regularyzacja L2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b66b20",
   "metadata": {},
   "source": [
    "- zapobiega przeuczeniu, zniechƒôca model do du≈ºych warto≈õci wag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983a2692",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01117357",
   "metadata": {},
   "source": [
    "-> Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05994e8",
   "metadata": {},
   "source": [
    "- losowo wy≈ÇƒÖczamy pewnƒÖ grupƒô neuron√≥w podczas uczenia (w r√≥≈ºnych iteracjach inne), oznaczmy ten procent przez $r$ \n",
    "- powoduje uniezale≈ºnianie wag od innych,\n",
    "podczas testowania korzystamy z pe≈Çni po≈ÇƒÖczonej sieci (kt√≥ra mo≈ºe byƒá traktowana jako u≈õrednienie tych z dropoutem), konieczna jest modyfikacja wyj≈õcia $z$ na $z(1-r)$,\n",
    "- efekt: uniezale≈ºnienie dzia≈Çania sieci od pojedynczych neuron√≥w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f041bf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bez\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, n_input_features, h1, h2, n_classes):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(n_input_features, h1)\n",
    "        self.linear2 = nn.Linear(h1, h2)\n",
    "        self.linear3 = nn.Linear(h2, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        l1 = self.linear1(x)\n",
    "        o1 = F.relu(l1)\n",
    "        l2 = self.linear2(o1)\n",
    "        o2 = F.relu(l2)\n",
    "        l3 = self.linear3(o2)\n",
    "        return l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1990bb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#z\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, n_input_features, h1, h2, n_classes):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(n_input_features, h1)\n",
    "        self.linear2 = nn.Linear(h1, h2)\n",
    "        self.linear3 = nn.Linear(h2, n_classes)\n",
    "        self.d1 = nn.Dropout(0.2) \n",
    "        self.d2 = nn.Dropout(0.2)\n",
    "    def forward(self, x):\n",
    "        o1 = F.relu(self.linear1(x))\n",
    "        o1 = self.d1(o1)\n",
    "        o2 = F.relu(self.linear2(o1))\n",
    "        o2 = self.d2(o2)\n",
    "        o3 = self.linear3(o2)\n",
    "    return o3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27975a5",
   "metadata": {},
   "source": [
    "-> Normalizacja"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6b8425",
   "metadata": {},
   "source": [
    "- Cel: ustabilizowanie i przyspieszenie procesu uczenia przez normalizacjƒô w ka≈ºdym \"batchu\", stosujemy najczƒô≈õciej przed funkcjƒÖ aktywacji, stabilizuje zakres warto≈õci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05237738",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_input_features, h1, h2, n_classes):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(n_input_features, h1)\n",
    "        self.bn1 = nn.BatchNorm1d(h1)\n",
    "        self.d1 = nn.Dropout(0.2)\n",
    "\n",
    "        self.linear2 = nn.Linear(h1, h2)\n",
    "        self.bn2 = nn.BatchNorm1d(h2)\n",
    "        self.d2 = nn.Dropout(0.2)\n",
    "\n",
    "        self.linear3 = nn.Linear(h2, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        o1 = self.linear1(x)\n",
    "        o1 = self.bn1(o1)\n",
    "        o1 = F.relu(o1)\n",
    "        o1 = self.d1(o1)\n",
    "\n",
    "        o2 = self.linear2(o1)\n",
    "        o2 = self.bn2(o2)\n",
    "        o2 = F.relu(o2)\n",
    "        o2 = self.d2(o2)\n",
    "\n",
    "        o3 = self.linear3(o2)\n",
    "        return o3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
